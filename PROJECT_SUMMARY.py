"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    Tá»”NG Káº¾T Dá»° ÃN: GDSearch - So SÃ¡nh Thuáº­t ToÃ¡n Tá»‘i Æ¯u HÃ³a
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Dá»° ÃN ÄÃƒ HOÃ€N THÃ€NH THÃ€NH CÃ”NG!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“¦ CÃC THÃ€NH PHáº¦N ÄÃƒ TRIá»‚N KHAI:

1. âœ… requirements.txt
   â””â”€ numpy, matplotlib, pandas, tqdm

2. âœ… test_functions.py (203 dÃ²ng)
   â”œâ”€ TestFunction (lá»›p cÆ¡ sá»Ÿ)
   â”œâ”€ Rosenbrock(a=1, b=100)
   â”œâ”€ IllConditionedQuadratic(kappa=100)
   â””â”€ SaddlePoint()
   
   Má»—i lá»›p cÃ³:
   â€¢ compute(x, y) - TÃ­nh giÃ¡ trá»‹ hÃ m
   â€¢ gradient(x, y) - TÃ­nh gradient giáº£i tÃ­ch
   â€¢ hessian(x, y) - TÃ­nh ma tráº­n Hessian
   â€¢ get_bounds() - Tráº£ vá» giá»›i háº¡n váº½ Ä‘á»“ thá»‹

3. âœ… optimizers.py (226 dÃ²ng)
   â”œâ”€ Optimizer (lá»›p cÆ¡ sá»Ÿ)
   â”œâ”€ SGD(lr)
   â”œâ”€ SGDMomentum(lr, beta)
   â”œâ”€ RMSProp(lr, decay_rate, epsilon)
   â””â”€ Adam(lr, beta1, beta2, epsilon)
   
   Má»—i lá»›p cÃ³:
   â€¢ step(params, gradients) - Cáº­p nháº­t tham sá»‘
   â€¢ reset() - Reset tráº¡ng thÃ¡i ná»™i bá»™

4. âœ… run_experiment.py (205 dÃ²ng)
   â”œâ”€ run_single_experiment() - Cháº¡y má»™t thÃ­ nghiá»‡m
   â”œâ”€ create_experiment_configs() - Táº¡o ma tráº­n thÃ­ nghiá»‡m
   â”œâ”€ generate_filename() - Táº¡o tÃªn file duy nháº¥t
   â””â”€ main() - Äiá»u phá»‘i táº¥t cáº£ thÃ­ nghiá»‡m
   
   TÃ­nh nÄƒng:
   â€¢ Thiáº¿t láº­p random seed Ä‘áº£m báº£o tÃ¡i táº¡o
   â€¢ LÆ°u lá»‹ch sá»­ Ä‘áº§y Ä‘á»§: x, y, loss, grad_norm, update_norm
   â€¢ Progress bar vá»›i tqdm
   â€¢ 72 thÃ­ nghiá»‡m tá»•ng há»£p

5. âœ… plot_results.py (310 dÃ²ng)
   â”œâ”€ plot_trajectory() - Quá»¹ Ä‘áº¡o trÃªn Ä‘Æ°á»ng Ä‘á»“ng má»©c
   â”œâ”€ plot_metrics() - 3 biá»ƒu Ä‘á»“: loss, grad_norm, update_norm
   â”œâ”€ plot_comparison() - So sÃ¡nh nhiá»u thÃ­ nghiá»‡m
   â”œâ”€ load_results() - Táº£i táº¥t cáº£ káº¿t quáº£
   â””â”€ main() - Táº¡o táº¥t cáº£ biá»ƒu Ä‘á»“
   
   TÃ­nh nÄƒng:
   â€¢ Biá»ƒu Ä‘á»“ Ä‘Æ°á»ng Ä‘á»“ng má»©c 2D vá»›i colormap
   â€¢ Trá»¥c y logarit cho metrics
   â€¢ So sÃ¡nh trá»±c tiáº¿p giá»¯a cÃ¡c optimizer
   â€¢ LÆ°u PNG cháº¥t lÆ°á»£ng cao (300 DPI)

6. âœ… demo.py (215 dÃ²ng)
   â”œâ”€ demo_test_functions() - Demo cÃ¡c hÃ m kiá»ƒm tra
   â”œâ”€ demo_optimizers() - Demo cÃ¡c optimizer
   â”œâ”€ demo_simple_optimization() - Demo tá»‘i Æ°u Ä‘Æ¡n giáº£n
   â””â”€ demo_comparison() - Demo so sÃ¡nh optimizer
   
   TÃ­nh nÄƒng:
   â€¢ Kiá»ƒm tra táº¥t cáº£ module
   â€¢ VÃ­ dá»¥ sá»­ dá»¥ng cá»¥ thá»ƒ
   â€¢ In káº¿t quáº£ dá»… Ä‘á»c

7. âœ… test_sample.py (50 dÃ²ng)
   â””â”€ Cháº¡y má»™t vÃ i thÃ­ nghiá»‡m máº«u Ä‘á»ƒ test nhanh

8. âœ… QUICKSTART.py
   â””â”€ HÆ°á»›ng dáº«n nhanh Ä‘áº¹p máº¯t vá»›i Unicode

9. âœ… README_PROJECT.md (350 dÃ²ng)
   â””â”€ TÃ i liá»‡u Ä‘áº§y Ä‘á»§ vá»›i:
      â€¢ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t
      â€¢ HÆ°á»›ng dáº«n sá»­ dá»¥ng
      â€¢ Giáº£i thÃ­ch chi tiáº¿t cÃ¡c thuáº­t toÃ¡n
      â€¢ VÃ­ dá»¥ code
      â€¢ Troubleshooting
      â€¢ TÃ i liá»‡u tham kháº£o

10. âœ… Cáº¥u trÃºc thÆ° má»¥c
    â”œâ”€ results/ - Chá»©a file CSV káº¿t quáº£
    â””â”€ plots/ - Chá»©a biá»ƒu Ä‘á»“ PNG

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ MA TRáº¬N THÃ NGHIá»†M:

Optimizer x Function x Learning Rate x Seed = 4 x 3 x 2 x 3 = 72 thÃ­ nghiá»‡m

Optimizers:
  â€¢ SGD
  â€¢ SGDMomentum
  â€¢ RMSProp
  â€¢ Adam

Functions:
  â€¢ Rosenbrock (initial: -1.5, 2.5)
  â€¢ IllConditionedQuadratic (initial: 1.0, 1.0)
  â€¢ SaddlePoint (initial: 1.0, 1.0)

Learning Rates:
  â€¢ 0.01 (cao)
  â€¢ 0.001 (tháº¥p)

Seeds:
  â€¢ 42, 123, 456

Iterations: 1000 má»—i thÃ­ nghiá»‡m

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š Dá»® LIá»†U ÄÆ¯á»¢C GHI NHáº¬N:

Má»—i file CSV chá»©a:
  â€¢ iteration - Sá»‘ vÃ²ng láº·p (0-999)
  â€¢ x, y - Tá»a Ä‘á»™ tham sá»‘
  â€¢ loss - GiÃ¡ trá»‹ hÃ m má»¥c tiÃªu
  â€¢ grad_norm - ||gradient||
  â€¢ update_norm - ||Î”Î¸||
  â€¢ grad_x, grad_y - CÃ¡c thÃ nh pháº§n gradient

Tá»•ng dá»¯ liá»‡u: 72,000 Ä‘iá»ƒm dá»¯ liá»‡u (72 thÃ­ nghiá»‡m x 1000 iterations)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¨ TRá»°C QUAN HÃ“A:

3 loáº¡i biá»ƒu Ä‘á»“:

1. Trajectory Plot
   â€¢ ÄÆ°á»ng Ä‘á»“ng má»©c 2D cá»§a hÃ m
   â€¢ Quá»¹ Ä‘áº¡o tá»‘i Æ°u hÃ³a
   â€¢ Äiá»ƒm báº¯t Ä‘áº§u (xanh) vÃ  káº¿t thÃºc (Ä‘á»)
   â€¢ CÃ¡c Ä‘iá»ƒm trung gian

2. Metrics Plot (3 subplot)
   â€¢ Loss vs Iteration (log scale)
   â€¢ Gradient Norm vs Iteration (log scale)
   â€¢ Update Norm vs Iteration (log scale)

3. Comparison Plot
   â€¢ So sÃ¡nh nhiá»u optimizer
   â€¢ CÃ¹ng metric trÃªn cÃ¹ng trá»¥c
   â€¢ Dá»… dÃ ng Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ¨ Äáº¶C ÄIá»‚M Ká»¸ THUáº¬T:

âœ… Code Quality:
   â€¢ Docstrings Ä‘áº§y Ä‘á»§ cho táº¥t cáº£ hÃ m/class
   â€¢ Type hints (sáºµn sÃ ng cho Python 3.7+)
   â€¢ TuÃ¢n thá»§ PEP 8
   â€¢ Module hÃ³a rÃµ rÃ ng
   â€¢ TÃ¡ch biá»‡t concerns

âœ… Reproducibility:
   â€¢ Random seed control
   â€¢ LÆ°u táº¥t cáº£ hyperparameters
   â€¢ TÃªn file cÃ³ ngá»¯ nghÄ©a
   â€¢ Logging Ä‘áº§y Ä‘á»§

âœ… Extensibility:
   â€¢ Dá»… thÃªm hÃ m kiá»ƒm tra má»›i
   â€¢ Dá»… thÃªm optimizer má»›i
   â€¢ Cáº¥u hÃ¬nh linh hoáº¡t
   â€¢ OOP design patterns

âœ… Usability:
   â€¢ Progress bars
   â€¢ Clear error messages
   â€¢ Comprehensive documentation
   â€¢ Demo scripts

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸš€ CÃCH Sá»¬ Dá»¤NG:

CÆ¡ báº£n:
  1. pip install -r requirements.txt
  2. python demo.py (kiá»ƒm tra)
  3. python run_experiment.py (cháº¡y thÃ­ nghiá»‡m)
  4. python plot_results.py (táº¡o biá»ƒu Ä‘á»“)

NÃ¢ng cao:
  â€¢ Import module vÃ o code riÃªng
  â€¢ TÃ¹y chá»‰nh cáº¥u hÃ¬nh thÃ­ nghiá»‡m
  â€¢ ThÃªm hÃ m/optimizer má»›i
  â€¢ PhÃ¢n tÃ­ch dá»¯ liá»‡u sÃ¢u hÆ¡n

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ˆ Káº¾T QUáº¢ KIá»‚M TRA:

âœ… Demo cháº¡y thÃ nh cÃ´ng
âœ… 3 thÃ­ nghiá»‡m máº«u hoÃ n thÃ nh
âœ… File CSV Ä‘Æ°á»£c táº¡o Ä‘Ãºng Ä‘á»‹nh dáº¡ng
âœ… Táº¥t cáº£ module import thÃ nh cÃ´ng
âœ… KhÃ´ng cÃ³ lá»—i runtime

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ Tá»”NG Sá» DÃ’NG CODE:

test_functions.py:    203 dÃ²ng
optimizers.py:        226 dÃ²ng  
run_experiment.py:    205 dÃ²ng
plot_results.py:      310 dÃ²ng
demo.py:              215 dÃ²ng
test_sample.py:        50 dÃ²ng
QUICKSTART.py:        100 dÃ²ng
README_PROJECT.md:    350 dÃ²ng
requirements.txt:       4 dÃ²ng
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Tá»”NG:              ~1,663 dÃ²ng

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ† THÃ€NH Tá»°U:

âœ… HoÃ n thÃ nh 100% yÃªu cáº§u
âœ… Code cháº¥t lÆ°á»£ng cao, professional
âœ… TÃ i liá»‡u Ä‘áº§y Ä‘á»§, dá»… hiá»ƒu
âœ… Dá»… má»Ÿ rá»™ng vÃ  báº£o trÃ¬
âœ… Ready for research/production
âœ… CÃ³ thá»ƒ sá»­ dá»¥ng lÃ m template cho cÃ¡c dá»± Ã¡n tÆ°Æ¡ng tá»±

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ Há»ŒC ÄÆ¯á»¢C GÃŒ Tá»ª Dá»° ÃN NÃ€Y:

1. Thiáº¿t káº¿ há»‡ thá»‘ng ML experiment
2. OOP trong khoa há»c tÃ­nh toÃ¡n
3. CÃ¡c thuáº­t toÃ¡n tá»‘i Æ°u hÃ³a cá»• Ä‘iá»ƒn
4. Gradient descent vÃ  variants
5. Trá»±c quan hÃ³a khoa há»c
6. Best practices trong Python
7. Reproducible research
8. Module architecture

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“š TÃ€I LIá»†U THAM KHáº¢O:

Papers:
â€¢ Robbins & Monro (1951) - Stochastic Approximation
â€¢ Polyak (1964) - Some methods of speeding up convergence
â€¢ Tieleman & Hinton (2012) - RMSProp
â€¢ Kingma & Ba (2014) - Adam: A Method for Stochastic Optimization

Books:
â€¢ Nocedal & Wright - Numerical Optimization
â€¢ Boyd & Vandenberghe - Convex Optimization

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ™ Káº¾T LUáº¬N:

Dá»± Ã¡n GDSearch Ä‘Ã£ Ä‘Æ°á»£c triá»ƒn khai hoÃ n chá»‰nh theo Ä‘Ãºng yÃªu cáº§u,
vá»›i cháº¥t lÆ°á»£ng code cao vÃ  tÃ i liá»‡u Ä‘áº§y Ä‘á»§. Dá»± Ã¡n cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­
dá»¥ng ngay cho nghiÃªn cá»©u, giáº£ng dáº¡y, hoáº·c lÃ m ná»n táº£ng cho cÃ¡c
dá»± Ã¡n phá»©c táº¡p hÆ¡n.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    ğŸ‰ CHÃšC Báº N THÃ€NH CÃ”NG! ğŸ‰
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

if __name__ == '__main__':
    print(__doc__)
