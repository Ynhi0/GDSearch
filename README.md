# GDSearch - Optimizer Dynamics Research Platform

A comprehensive Python framework for comparing gradient descent algorithms on 2D test functions and neural networks (MNIST/CIFAR-10/IMDB). Features systematic hyperparameter tuning, convergence analysis, curvature tracking, loss landscape visualization, **multi-seed experiments**, **statistical analysis**, and **NLP support**.

## ğŸ¯ Features

### Core Capabilities
- âœ… **4 Optimization Algorithms:** SGD, SGD+Momentum, RMSProp, Adam/AdamW
- âœ… **7 Test Functions:** Rosenbrock, Ill-Conditioned Quadratic, Saddle Point, Rastrigin, Ackley, Sphere, Schwefel
- âœ… **High-Dimensional Benchmarks:** Rastrigin, Ackley, Sphere, Schwefel (N-dimensional, tested up to 100D)
- âœ… **Neural Networks:** SimpleMLP (MNIST), SimpleCNN/ConvNet (CIFAR-10), **ResNet-18** (CIFAR-10), NLP models (IMDB)
- âœ… **Deep Architectures:** ResNet-18 (18 layers, 11M parameters, residual connections)
- âœ… **NLP Models:** SimpleRNN, SimpleLSTM, BiLSTM, TextCNN (Kim 2014)
- âœ… **Systematic Hyperparameter Tuning:** Two-stage pipeline (LR sweep â†’ parameter sweep) + Optuna integration
- âœ… **Learning Rate Schedulers:** Step, Cosine, Exponential, Warmup, OneCycle, and more
- âœ… **Convergence Detection:** Dual conditions (grad norm threshold OR loss delta)
- âœ… **Advanced Analysis:**
  - Hessian eigenvalue tracking (Î»_min, Î»_max, condition number)
  - Loss landscape 1D/2D visualization
  - Per-layer gradient norms
  - Curvature analysis (trajectory turning angles)
  - Generalization gap monitoring

### ğŸ†• Scientific Rigor
- âœ… **Multi-Seed Experiments:** Run experiments with multiple random seeds for statistical reliability
- âœ… **Statistical Analysis:** T-tests, effect sizes (Cohen's d), 95% confidence intervals
- âœ… **Power Analysis:** Statistical power calculation and sample size determination
- âœ… **Multiple Comparison Corrections:** Bonferroni, Holm-Bonferroni, Benjamini-Hochberg (FDR)
- âœ… **Normality Testing:** Shapiro-Wilk, Anderson-Darling, Kolmogorov-Smirnov
- âœ… **Non-parametric Tests:** Mann-Whitney U, Wilcoxon signed-rank (for non-normal data)
- âœ… **Auto-Test Selection:** Automatically choose appropriate test based on normality
- âœ… **Interactive Visualizations:** Plotly-based 2D/3D plots, animations, loss landscapes
- âœ… **Error Bar Visualization:** Plots with mean Â± std bands
- âœ… **Unit Tests:** 177 tests verifying gradients, optimizers, schedulers, NLP, ResNet, high-dim functions, statistics, and visualizations (pytest)
- âœ… **Input Validation:** Comprehensive error checking and input sanitization
- âœ… **Ablation Studies:** Component-wise isolation to quantify contributions
- âœ… **Baseline Comparisons:** Compare custom implementations with PyTorch built-ins
- âœ… **GPU Validation:** Kaggle experiments for large-scale training (ResNet-18: 85.51% on CIFAR-10)

## ğŸ“ Project Structure

```
GDSearch/
â”œâ”€â”€ src/                        # ğŸ†• All source code (organized!)
â”‚   â”œâ”€â”€ core/                   # Core implementations
â”‚   â”‚   â”œâ”€â”€ optimizers.py           # SGD, Adam, RMSProp implementations (2D + ND)
â”‚   â”‚   â”œâ”€â”€ test_functions.py       # 2D test functions with analytic derivatives
â”‚   â”‚   â”œâ”€â”€ models.py               # PyTorch NN models (MLP, CNN, ConvNet, ResNet-18)
â”‚   â”‚   â”œâ”€â”€ nlp_models.py           # ğŸ†• NLP models (RNN, LSTM, BiLSTM, TextCNN)
â”‚   â”‚   â”œâ”€â”€ nlp_data_utils.py       # ğŸ†• IMDB dataset loading & vocabulary
â”‚   â”‚   â”œâ”€â”€ pytorch_optimizers.py   # ğŸ†• PyTorch wrappers for custom optimizers
â”‚   â”‚   â”œâ”€â”€ data_utils.py           # MNIST/CIFAR-10 loaders
â”‚   â”‚   â”œâ”€â”€ lr_schedulers.py        # ğŸ†• Learning rate scheduling (9 schedulers)
â”‚   â”‚   â”œâ”€â”€ optuna_tuner.py         # ğŸ†• Optuna hyperparameter optimization
â”‚   â”‚   â””â”€â”€ validation.py           # Input validation & error handling
â”‚   â”‚
â”‚   â”œâ”€â”€ experiments/            # Experiment runners
â”‚   â”‚   â”œâ”€â”€ run_experiment.py       # 2D experiments with Hessian tracking
â”‚   â”‚   â”œâ”€â”€ run_nn_experiment.py    # NN training with convergence detection
â”‚   â”‚   â”œâ”€â”€ run_multi_seed.py       # Multi-seed experiment framework
â”‚   â”‚   â””â”€â”€ run_full_analysis.py    # Complete pipeline: experiments â†’ stats â†’ plots
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/               # Statistical analysis
â”‚   â”‚   â”œâ”€â”€ statistical_analysis.py # T-tests, effect sizes, confidence intervals
â”‚   â”‚   â”œâ”€â”€ sensitivity_analysis.py # Hyperparameter sensitivity
â”‚   â”‚   â”œâ”€â”€ ablation_study.py       # Component-wise ablation
â”‚   â”‚   â””â”€â”€ baseline_comparison.py  # Compare with PyTorch optimizers
â”‚   â”‚
â”‚   â””â”€â”€ visualization/          # Plotting utilities
â”‚       â”œâ”€â”€ plot_results.py         # Comprehensive plotting (with error bars!)
â”‚       â”œâ”€â”€ plot_eigenvalues.py     # Hessian eigenvalue visualization
â”‚       â””â”€â”€ loss_landscape.py       # Loss surface probing
â”‚
â”œâ”€â”€ tests/                      # Unit tests (123 tests, 100% passing)
â”‚   â”œâ”€â”€ test_gradients.py       # Numerical gradient verification
â”‚   â”œâ”€â”€ test_optimizers.py      # Optimizer correctness tests
â”‚   â”œâ”€â”€ test_lr_schedulers.py   # ğŸ†• LR scheduler tests
â”‚   â”œâ”€â”€ test_optuna_tuner.py    # ğŸ†• Optuna integration tests
â”‚   â”œâ”€â”€ test_nlp.py             # ğŸ†• NLP models & data tests
â”‚   â”œâ”€â”€ test_resnet.py          # ğŸ†• ResNet-18 architecture tests
â”‚   â””â”€â”€ test_highdim_functions.py  # ğŸ†• High-dimensional function tests
â”‚
â”œâ”€â”€ configs/                    # Experiment configurations
â”‚   â”œâ”€â”€ nn_tuning.json          # MNIST hyperparameter sweeps
â”‚   â””â”€â”€ cifar10_tuning.json     # CIFAR-10 configurations
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ run_all.py              # Complete reproducibility pipeline
â”‚   â”œâ”€â”€ tune_nn.py              # Two-stage hyperparameter tuning
â”‚   â”œâ”€â”€ demo_imdb_training.py   # ğŸ†• IMDB sentiment analysis demo
â”‚   â”œâ”€â”€ demo_highdim_optimization.py  # ğŸ†• High-dimensional function optimization
â”‚   â””â”€â”€ generate_summaries.py   # Quantitative & qualitative tables
â”‚
â”œâ”€â”€ docs/                       # ğŸ†• All documentation (consolidated!)
â”‚   â”œâ”€â”€ INDEX.md                # Documentation navigation hub
â”‚   â”œâ”€â”€ LIMITATIONS.md          # Known limitations & assumptions
â”‚   â”œâ”€â”€ MULTISEED_GUIDE.md      # Guide for multi-seed experiments
â”‚   â”œâ”€â”€ IMPROVEMENT_PROGRESS.md # Progress tracking
â”‚   â”œâ”€â”€ CRITICAL_VALIDATION_REPORT.md  # Scientific validation
â”‚   â”œâ”€â”€ REPORT.md               # Synthesis report with ablation study
â”‚   â”œâ”€â”€ PHASE11_NLP_SUMMARY.md  # NLP implementation summary
â”‚   â”œâ”€â”€ PHASE12_RESNET_SUMMARY.md  # ğŸ†• ResNet-18 deep network summary
â”‚   â””â”€â”€ hypothesis_matrix.md    # Theory â‡„ Experiment mapping
â”‚
â”œâ”€â”€ kaggle/                     # ğŸ†• Kaggle GPU experiments
â”‚   â”œâ”€â”€ QUICKSTART.md           # How to run experiments on Kaggle
â”‚   â”œâ”€â”€ INSTRUCTIONS.md         # Detailed step-by-step guide
â”‚   â”œâ”€â”€ resnet18_cifar10.py     # ResNet-18 training script
â”‚   â”œâ”€â”€ RESULTS_resnet18.md     # ğŸ†• Kaggle experiment results (85.51% accuracy)
â”‚   â””â”€â”€ verify_local.py         # Local verification script
â”‚
â”œâ”€â”€ results/                    # CSV outputs (experiments, summaries)
â”œâ”€â”€ plots/                      # All visualizations (PNG)
â”œâ”€â”€ data/                       # Dataset utilities
â”‚
â”œâ”€â”€ pyproject.toml              # ğŸ†• Modern Python project configuration
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone or navigate to the project
cd /workspaces/GDSearch

# Install dependencies
pip install -r requirements.txt
```

**Dependencies:** numpy, pandas, matplotlib, scipy, torch, torchvision, tqdm, pytest

### Running Tests (Verify Installation)

```bash
# Run all tests (gradients + optimizers)
pytest tests/ -v

# Expected: 35 tests passed âœ…
```

### Running Experiments

#### Option 1: Multi-Seed Statistical Analysis (Recommended) ğŸ†•
```bash
# Full pipeline: experiments â†’ aggregation â†’ stats â†’ plots
python src/experiments/run_full_analysis.py \
    --config configs/nn_tuning.json \
    --seeds 1,2,3,4,5 \
    --compare AdamW-SGDMomentum,Adam-RMSProp

# Quick test with 3 seeds
python src/experiments/run_full_analysis.py --seeds 1,2,3
```

**Output:**
- Multi-seed results with mean Â± std
- Statistical comparisons (t-tests, p-values, effect sizes)
- Plots with error bars
- Aggregated JSON summary

#### Option 2: Ablation Study (Component Analysis) ğŸ†•
```bash
# Test each optimizer component in isolation
python src/analysis/ablation_study.py

# Components tested:
#   1. SGD baseline (no momentum, no adaptive LR)
#   2. SGD + Momentum
#   3. RMSProp (adaptive LR only)
#   4. Adam (full)
#   5. Adam with L2 regularization
#   6. AdamW (decoupled weight decay)
```

#### Option 3: Baseline Comparison ğŸ†•
```bash
# Compare custom implementations with PyTorch built-ins
python src/analysis/baseline_comparison.py

# Compares:
#   - Custom Adam vs torch.optim.Adam
#   - Custom AdamW vs torch.optim.AdamW
#   - Custom SGD+Momentum vs torch.optim.SGD
#   - Custom RMSProp vs torch.optim.RMSProp
```

#### Option 4: Traditional Single-Seed Pipeline
```bash
# Run everything: 2D + NN tuning + summaries + plots
python scripts/run_all.py

# Skip specific phases
python scripts/run_all.py --skip-2d              # Skip 2D experiments
python scripts/run_all.py --skip-tuning          # Skip NN hyperparameter tuning
python scripts/run_all.py --summaries-only       # Only regenerate summaries

# Quick mode (reduced iterations)
python scripts/run_all.py --quick
```

#### Option 5: Step-by-Step (Learning Mode)

```bash
# 1. Run 2D test function experiments (with Hessian eigenvalue tracking)
python src/experiments/run_experiment.py

# 2. Run neural network hyperparameter tuning
python scripts/tune_nn.py

# 3. Generate loss landscape visualizations
python src/visualization/loss_landscape.py

# 4. Create summary tables and plots
python scripts/generate_summaries.py

# 5. Visualize Hessian eigenvalues (optional)
python src/visualization/plot_eigenvalues.py
```

#### Option 6: Quick Demo
```bash
# Run short MNIST demo (2 epochs)
python scripts/nn_workflow.py
```

#### Option 7: NLP Experiments (NEW! ğŸ†•)
```bash
# Train sentiment classifier on IMDB dataset
python scripts/demo_imdb_training.py \
    --model lstm \
    --optimizer adam \
    --epochs 5 \
    --train-size 5000 \
    --test-size 1000

# Available models: rnn, lstm, bilstm, textcnn
# Available optimizers: sgd, sgd_momentum, adam, rmsprop

# Quick test with small dataset
python scripts/demo_imdb_training.py \
    --epochs 2 \
    --train-size 1000 \
    --test-size 200
```

**NLP Models:**
- **SimpleRNN**: Vanilla recurrent network for baseline
- **SimpleLSTM**: Long Short-Term Memory with forget gates
- **BiLSTM**: Bidirectional LSTM for context from both directions
- **TextCNN**: Kim 2014 architecture with multiple filter sizes

**Custom Optimizer Integration:**
- All custom optimizers now support arbitrary-dimensional parameters
- Backward compatible with 2D test functions
- PyTorch-compatible wrappers for seamless neural network training

## ğŸ“Š Key Outputs

### Results Directory (`results/`)
- **Experiment CSVs:** `NN_<model>_<dataset>_<optimizer>_lr<lr>_seed<seed>[_tag].csv`
  - Tags: `sweepLR`, `sweepWD`, `sweepMOM`, `final`
- **Summary Tables:**
  - `summary_quantitative.csv`: Final metrics, convergence iters/time
  - `summary_qualitative.csv/md`: Smoothness, oscillation ratings

### Plots Directory (`plots/`)

**2D Visualizations:**
- `*_trajectory.png`: Optimization paths with contours
- `*_eigenvalues.png`: Î»_min, Î»_max, condition number evolution
- `dynamics_triplet_*.png`: Update/grad/curvature vs iteration
- `adam_trajectory_grid_*.png`: Î²1Ã—Î²2 hyperparameter grid
- `sgdm_trajectory_series_*.png`: Momentum sweep (Î² values)
- `trajectory_3d_*.png`: 3D trajectory on function surface

**Neural Network Visualizations:**
- `*_gen_gap.png`: Generalization gap + test accuracy (dual y-axis)
- `*_layer_grads.png`: Per-layer gradient norms at epochs [1, 10, 20]
- `loss_landscape_1d.png`: 1D loss slice along random direction
- `loss_landscape_2d_surface.png`: 2D loss surface around trained weights
- `loss_landscape_2d_contour.png`: Contour map of loss landscape

## ğŸ“– Understanding the Outputs

### Convergence Detection
The system automatically detects convergence using dual conditions:
- **Condition 1:** `grad_norm < 1e-6`
- **Condition 2:** `abs(loss[t] - loss[t-200]) < 1e-7` (windowed loss delta)

When convergence is detected, a `meta` row is logged with `(global_step, time_sec)`.

### Hessian Eigenvalue Interpretation
- **Î»_max, Î»_min:** Largest and smallest curvatures
- **Condition number (Îº = |Î»_max / Î»_min|):** Measures local ill-conditioning
- **Eigenvalue product (Î»_max Ã— Î»_min):**
  - `> 0`: Locally convex (both eigenvalues same sign)
  - `< 0`: Saddle point (eigenvalues opposite signs)

### Generalization Gap
`gen_gap = test_loss - train_loss`

Smaller gap indicates better generalization. Our findings:
- **AdamW:** Fast convergence but larger gen-gap (~0.15)
- **SGD+Momentum:** Slower start but smaller gen-gap (~0.08), better generalization

## ğŸ”¬ Advanced Usage

### Custom Hyperparameter Tuning

Edit `configs/nn_tuning.json`:
```json
{
  "dataset": "MNIST",
  "model": "SimpleMLP",
  "sweeps": [
    {
      "optimizer": "AdamW",
      "lr_values": [0.1, 0.01, 0.001, 0.0001],
      "weight_decay_values": [0.0, 0.0001, 0.0005],
      "epochs": 3
    }
  ],
  "final": {
    "epochs": 20,
    "capture_layer_grad_epochs": [1, 10, 20]
  },
  "convergence": {
    "grad_norm_threshold": 1e-6,
    "loss_delta_threshold": 1e-7,
    "loss_window": 200
  }
}
```

Then run: `python tune_nn.py`

### Adding Custom Test Functions

```python
# In src/core/test_functions.py
class MyFunction(TestFunction):
    def compute(self, x, y):
        return x**2 + y**2  # Your function here
    
    def gradient(self, x, y):
        return 2*x, 2*y  # Analytic gradient
    
    def hessian(self, x, y):
        return np.array([[2, 0], [0, 2]])  # Analytic Hessian
```

### Adding Custom Optimizers

```python
# In src/core/optimizers.py
class MyOptimizer(Optimizer):
    def __init__(self, lr=0.01, beta=0.9):
        super().__init__()
        self.lr = lr
        self.beta = beta
        self.state = {}  # Internal state
    
    def step(self, params, gradients):
        # Your update rule here
        new_params = ...
        return new_params
    
    def reset(self):
        self.state = {}
```

## ğŸ“ˆ Results & Insights

### Ablation Study: Optimizer Comparison

From `REPORT.md`:

| Optimizer | MNIST Test Acc | Gen Gap | Convergence Speed | Landscape |
|-----------|----------------|---------|-------------------|-----------|
| **AdamW** | ~97.5% | ~0.15 | Fast (early epochs) | Sharper minima |
| **SGD+Momentum** | ~97.6% | ~0.08 | Slower start | Flatter minima |

**Key Takeaway:** Start with AdamW for rapid prototyping, switch to SGD+Momentum for final training when generalization is critical.

### Theory â‡„ Experiment Validation

See `hypothesis_matrix.md` for complete mapping:

| Hypothesis | Experiment | Visualization |
|------------|------------|---------------|
| Momentum reduces zig-zag | SGD vs SGDM on Rosenbrock | `sgdm_trajectory_series_*.png` |
| Adam accelerates early | MNIST AdamW vs SGD-Momentum | `*_gen_gap.png` |
| Sharp vs flat minima | Loss landscape around trained weights | `loss_landscape_*.png` |
| Layer-wise scaling | Per-layer gradient norms | `*_layer_grads.png` |

## ğŸ› ï¸ Troubleshooting

**Issue:** Overflow error on Rosenbrock with high momentum
- **Solution:** Reduce learning rate (try 0.001 instead of 0.01)

**Issue:** CUDA out of memory
- **Solution:** Reduce `batch_size` in config or use CPU (default)

**Issue:** Missing eigenvalue columns in old CSV files
- **Solution:** Re-run `python run_experiment.py` to regenerate with new format

## ğŸ“š Citation

If you use this codebase in your research, please cite:

```
@software{gdsearch2025,
  title={GDSearch: Optimizer Dynamics Research Platform},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/GDSearch}
}
```

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Basin-of-attraction maps
- Noisy gradient experiments
- Additional test functions (Beale, Himmelblau, etc.)
- More NN architectures (ResNet, Transformer)

## ğŸ“ Contact

For questions or issues, please open a GitHub issue or contact [your-email@example.com]

---

**Last Updated:** November 3, 2025