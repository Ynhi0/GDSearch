{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d721351",
   "metadata": {},
   "source": [
    "# MNIST Publication Experiments (Kaggle Notebook)\n",
    "\n",
    "This notebook runs a publication-quality MNIST experiment suite:\n",
    "- 5 optimizers × N seeds\n",
    "- 10 epochs per run (configurable)\n",
    "- Saves per-run CSVs and a statistical comparison CSV\n",
    "\n",
    "Tips:\n",
    "- Enable GPU (Notebook Settings → Accelerator: GPU)\n",
    "- Enable Internet to download MNIST from torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b624262",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "Adjust seeds, epochs, and batch size here. Set `QUICK=True` for a short run (3 seeds, 3 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b69c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "SEEDS = list(range(1, 11))  # 1..10\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "RESULTS_DIR = 'results'\n",
    "QUICK = False  # if True, overrides to seeds=[1,2,3], epochs=3\n",
    "\n",
    "if QUICK:\n",
    "    SEEDS = [1, 2, 3]\n",
    "    EPOCHS = 3\n",
    "\n",
    "print('Seeds:', SEEDS)\n",
    "print('Epochs:', EPOCHS)\n",
    "print('Batch size:', BATCH_SIZE)\n",
    "print('Results dir:', RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67012d",
   "metadata": {},
   "source": [
    "## Imports and Helpers\n",
    "Model, data loaders, training, and evaluation utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, math, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def get_data_loaders(batch_size: int, num_workers: int = 2, pin_memory: bool = True):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "    # Kaggle path\n",
    "    root = '/kaggle/working/data' if os.path.exists('/kaggle/working') else './data'\n",
    "    train_dataset = datasets.MNIST(root=root, train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root=root, train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                             num_workers=num_workers, pin_memory=pin_memory)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.size(0)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == target).sum().item()\n",
    "        total += data.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712d478",
   "metadata": {},
   "source": [
    "## Run Experiments\n",
    "Runs 5 optimizers × N seeds and saves per-run CSVs to `RESULTS_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d1b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_experiment(optimizer_name: str, seed: int, lr: float, epochs: int, batch_size: int, results_dir: Path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    set_seed(seed)\n",
    "    train_loader, test_loader = get_data_loaders(batch_size)\n",
    "    model = SimpleMLP().to(device)\n",
    "    if optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'SGD_Momentum':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    elif optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'AdamW':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    elif optimizer_name == 'AMSGrad':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown optimizer: {optimizer_name}')\n",
    "    history = []\n",
    "    start = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device)\n",
    "        test_loss, test_acc = evaluate(model, test_loader, device)\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'train_acc': train_acc, 'test_loss': test_loss, 'test_acc': test_acc})\n",
    "        tqdm.write(f'Seed {seed} | {optimizer_name} | Epoch {epoch}/{epochs} | ' +\n",
    "                   f'train_loss={train_loss:.4f}, train_acc={train_acc:.2%}, test_loss={test_loss:.4f}, test_acc={test_acc:.2%}')\n",
    "    elapsed = time.time() - start\n",
    "    df = pd.DataFrame(history)\n",
    "    Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
    "    out_name = f'NN_SimpleMLP_MNIST_{optimizer_name}_lr{lr}_seed{seed}_publication.csv'\n",
    "    df.to_csv(Path(results_dir) / out_name, index=False)\n",
    "    return df, elapsed\n",
    "\n",
    "def run_suite(seeds, epochs, batch_size, results_dir: str):\n",
    "    optimizers = [('SGD', 0.01), ('SGD_Momentum', 0.05), ('Adam', 0.001), ('AdamW', 0.001), ('AMSGrad', 0.001)]\n",
    "    total_runs = len(optimizers) * len(seeds)\n",
    "    print(f'Total experiments to run: {total_runs}')\n",
    "    completed = 0\n",
    "    durations = []\n",
    "    for opt_name, lr in optimizers:\n",
    "        for seed in seeds:\n",
    "            try:\n",
    "                tqdm.write(f\n",
    "                _, dur = run_single_experiment(opt_name, seed, lr, epochs, batch_size, Path(results_dir))\n",
    "                durations.append(dur)\n",
    "                completed += 1\n",
    "            except Exception as e:\n",
    "                tqdm.write(f'❌ Error: {e}')\n",
    "    print(f\n",
    ")\n",
    "    if durations:\n",
    "        avg_min = np.mean(durations) / 60.0\n",
    "        print(f'Avg time per run: {avg_min:.2f} min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a17b7b",
   "metadata": {},
   "source": [
    "## Statistical Comparison\n",
    "Paired tests with Holm-Bonferroni correction (saves CSV to results dir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a321444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(results_dir: str):\n",
    "    import glob, re\n",
    "    patterns = {\n",
    "        'SGD': f\n",
    ",\n",
    "        'SGD_Momentum': f\n",
    ",\n",
    "        'Adam': f\n",
    ",\n",
    "        'AdamW': f\n",
    ",\n",
    "        'AMSGrad': f\n",
    ",\n",
    "    }\n",
    "    data = {}\n",
    "    for opt, pattern in patterns.items():\n",
    "        vals = {}\n",
    "        for f in glob.glob(pattern):\n",
    "            m = re.search(r'seed(\\d+)', f)\n",
    "            if not m:\n",
    "                continue\n",
    "            seed = int(m.group(1))\n",
    "            df = pd.read_csv(f)\n",
    "            final_row = df.iloc[-1]\n",
    "            vals[seed] = final_row['test_loss']\n",
    "        data[opt] = vals\n",
    "    comparisons = [\n",
    "        ('Adam', 'SGD'), ('AdamW', 'Adam'), ('AMSGrad', 'Adam'), ('SGD_Momentum', 'SGD'),\n",
    "        ('AdamW', 'SGD'), ('AMSGrad', 'SGD'), ('AMSGrad', 'AdamW'), ('SGD_Momentum', 'Adam'),\n",
    "    ]\n",
    "    rows = []\n",
    "    for A, B in comparisons:\n",
    "        common = sorted(list(set(data.get(A, {}).keys()) & set(data.get(B, {}).keys())))\n",
    "        if len(common) < 3:\n",
    "            continue\n",
    "        vals_A = np.array([data[A][s] for s in common])\n",
    "        vals_B = np.array([data[B][s] for s in common])\n",
    "        _, pA = stats.shapiro(vals_A)\n",
    "        _, pB = stats.shapiro(vals_B)\n",
    "        if pA > 0.05 and pB > 0.05:\n",
    "            stat_name = 'Paired t-test'\n",
    "            _, p = stats.ttest_rel(vals_A, vals_B)\n",
    "            d = (vals_A - vals_B).mean() / (vals_A - vals_B).std(ddof=1)\n",
    "        else:\n",
    "            stat_name = 'Wilcoxon'\n",
    "            W, p = stats.wilcoxon(vals_A, vals_B)\n",
    "            n = len(vals_A)\n",
    "            d = 1 - (2 * W) / (n * (n + 1))\n",
    "        rows.append({'Optimizer A': A, 'Optimizer B': B, 'n_common_seeds': len(common), 'Mean A': float(vals_A.mean()), 'Std A': float(vals_A.std(ddof=1)), 'Mean B': float(vals_B.mean()), 'Std B': float(vals_B.std(ddof=1)), 'Test': stat_name, 'p-value': float(p), 'Effect size (d or r)': float(d)})\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print('No comparisons could be computed (need >=3 common seeds per pair).')\n",
    "        return None\n",
    "    m = len(df)\n",
    "    order = np.argsort(df['p-value'].values)\n",
    "    holm_sig = np.zeros(m, dtype=bool)\n",
    "    alpha = 0.05\n",
    "    for k, idx in enumerate(order):\n",
    "        if df.loc[idx, 'p-value'] < alpha / (m - k):\n",
    "            holm_sig[idx] = True\n",
    "        else:\n",
    "            break\n",
    "    df['Significant (Holm-Bonferroni)'] = holm_sig\n",
    "    out = Path(results_dir) / 'mnist_statistical_comparisons_publication.csv'\n",
    "    Path(results_dir).mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out, index=False)\n",
    "    print(f'Saved statistical comparisons to: {out}')\n",
    "    df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94882c73",
   "metadata": {},
   "source": [
    "## Execute Suite\n",
    "Runs all experiments and computes statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*60)\n",
    "print('MNIST Publication Experiments (Notebook)')\n",
    "print('='*60)\n",
    "print('Device:', 'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Seeds:', SEEDS)\n",
    "print('Epochs:', EPOCHS)\n",
    "print('Batch size:', BATCH_SIZE)\n",
    "print('Results dir:', RESULTS_DIR)\n",
    "print('='*60)\n",
    "\n",
    "run_suite(SEEDS, EPOCHS, BATCH_SIZE, RESULTS_DIR)\n",
    "compute_statistics(RESULTS_DIR)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b34c0",
   "metadata": {},
   "source": [
    "## Inspect Outputs\n",
    "Lists generated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ff35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = sorted(glob.glob(f'{RESULTS_DIR}/NN_SimpleMLP_MNIST_*_publication.csv'))\n",
    "print(f'Per-run CSVs: {len(files)} files')\n",
    "for f in files[:10]:\n",
    "    print(' -', f)\n",
    "if len(files) > 10:\n",
    "    print(f' ... and {len(files)-10} more')\n",
    "\n",
    "stat_path = Path(RESULTS_DIR) / 'mnist_statistical_comparisons_publication.csv'\n",
    "print('Stats CSV exists:', stat_path.exists(), '|', stat_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
